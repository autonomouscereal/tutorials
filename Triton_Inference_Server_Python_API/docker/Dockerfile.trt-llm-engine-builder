ARG BASE_IMAGE=nvcr.io/nvidia/tritonserver
ARG BASE_IMAGE_TAG=23.12-trtllm-python-py3

FROM ${BASE_IMAGE}:${BASE_IMAGE_TAG} as trt-llm-engine-builder

ARG TRT_LLM_BACKEND_REPO=https://github.com/triton-inference-server/tensorrtllm_backend.git
ARG TRT_LLM_BACKEND_TAG=r23.12

# Update the submodule TensorRT-LLM repository
RUN git clone -b $TRT_LLM_BACKEND_TAG $TRT_LLM_BACKEND_REPO
WORKDIR tensorrtllm_backend
RUN apt-get update; apt-get install -y git-lfs
RUN git lfs install &&  git lfs pull
RUN git submodule update --init --recursive


# TensorRT-LLM is required for generating engines. You can skip this step if
# you already have the package installed. If you are generating engines within
# the Triton container, you have to install the TRT-LLM package.
RUN (cd tensorrt_llm && \
    bash docker/common/install_cmake.sh && \
    export PATH=/usr/local/cmake/bin:$PATH && \
    python3 ./scripts/build_wheel.py --trt_root="/usr/local/tensorrt" && \
    pip3 install ./build/tensorrt_llm*.whl)

# # Go to the tensorrt_llm/examples/gpt directory
# cd tensorrt_llm/examples/gpt

# # Download weights from HuggingFace Transformers
# rm -rf gpt2 && git clone https://huggingface.co/gpt2-medium gpt2
# pushd gpt2 && rm pytorch_model.bin model.safetensors && wget -q https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin && popd

# # Convert weights from HF Tranformers to FT format
# python3 hf_gpt_convert.py -p 8 -i gpt2 -o ./c-model/gpt2 --tensor-parallelism 4 --storage-type float16

# # Build TensorRT engines
# python3 build.py --model_dir=./c-model/gpt2/4-gpu/ \
#                  --world_size=4 \
#                  --dtype float16 \
#                  --use_inflight_batching \
#                  --use_gpt_attention_plugin float16 \
#                  --paged_kv_cache \
#                  --use_gemm_plugin float16 \
#                  --remove_input_padding \
#                  --use_layernorm_plugin float16 \
#                  --hidden_act gelu \
#                  --parallel_build \
#                  --output_dir=engines/fp16/4-gpu
